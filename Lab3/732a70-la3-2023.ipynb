{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Functional programming, and declarative patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Student:__ abcde123\n",
    "\n",
    "__Student:__ abcde123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer: Functional programming in Python does not always lead to the fastest possible code, and is often not considered the *pythonic* approach. However, functional programming is the basis for many concurrent systems (the MapReduce programming model which many big data systems, e.g. Hadoop, relies on gets its name from the *map* and *reduce* functions mentioned below). Python is a multi-paradigm language, and functional programming is one of the main paradigms one can use. To understand how and when to do this, it is necessary to do things in a non-*pythonic* way in order to cover the basics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General instructions\n",
    "\n",
    "In this lab there are some general rules you should keep in mind to make sure you are on the correct path in your solutions.\n",
    "\n",
    "#### Rules\n",
    "1. You are not allowed to use `while` or `for` statements unless this is explicitly allowed in the task.\n",
    "2. You are not allowed to use global variables (other than for functions defined in the global environment).\n",
    "3. Code stubs should be viewed as fixed, you are only allowed to add code, the only code you are allowed to change is `pass` statements, which you should remove.\n",
    "4. You should refrain from using the `list` datatype unless otherwise specified and instead use `tuple`. One of the strengths of functional programming is its focus on immutable data types (this is why functional programming and concurrency goes so well together). Incidentally, one might find speedups when using the immutable tuples instead of lists.\n",
    "\n",
    "#### Advice\n",
    "1. Avoid local variables unless you are certain they are necessary, in most cases you won't need to use local variables. (altermatively, use local variables to your hearts content, but when your solution works, try to eliminate them, you should be able to eliminate most of them, over time, you might find that you don't need them.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Higher order functions (HOF)\n",
    " \n",
    "A _higher-order function_ is a function which operates on other functions. What this means exactly is disputed, but we will call any function which returns a function or takes a function as an argument a higher-order function. (Conversely, a function neither taking another function as input nor returning a function we will refer to as a _first-order function_)\n",
    "\n",
    "In R you have encountered these when, for instance, using the `apply` family of functions, which are all versions of what is called a `map` function in functional programming (see below).\n",
    "\n",
    "When using higher-order functions, it is often useful to create simple anonymous functions at the place in the code where they are used, rather than defining a new named function in one place only to call it in a single other place. In R, all functions are created in this way with the `function` keyword, but they are usually assigned to global names with standard assignment (`<-`). Python provides similar functionality using the `lambda` keyword (name inspired by Alonzo Church's [$\\lambda$-calculus](https://www.youtube.com/watch?v=eis11j_iGMs) which has inspired much of functional programming) with which we can create anonymous functions. Of course, we can also pass named functions to higher-order functions, which is usually the case when the function is predefined, general enough to be used in more than one place, or complex enough to warrant separate definition and documentation for the sake of clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 The three standard functions `map`, `reduce` and `filter`\n",
    "\n",
    "There are three standard cases which are widely applicable and many other higher-order functions are special cases or combinations of these. They are: `map`, apply a function on each element in a sequence, `filter`, keep (or conversely, remove) elements from a sequence according to some condition, and `reduce`, combine the elements in a sequence. The `map` function takes a sequence and a function (usually of 1 parameter) which is to be applied to each element of the sequence and might return anything, this function is assumed not to have side effects. The `filter` function takes a function (usually of 1 parameter) which returns a boolean value used to indicate which elements are to be kept. The `reduce` function takes a function (usually of 2 parameters) which is used to combine the elements in the sequence.\n",
    "\n",
    "In Python, `map` and `filter` are standard built-in functions. Since Python 3, the `reduce` function needs to be imported from the `functools` module.\n",
    "\n",
    "Many more advanced functions, of any order, can be created by combining these three higher-order functions.\n",
    "\n",
    "A note from last year: usually, the `reduce` function is more difficult to grasp than `map` and `filter` but I found this blog-post by AndrÃ© Burgaud to be a nice introduction to `reduce`. Note that Burgaud talks about the more general _fold_ concept rather than `reduce`, which is a special case of fold often called _left fold_ (this is covered in more detail in the post). https://www.burgaud.com/foldl-foldr-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Implement a function `mysum` which computes the sum of a list or tuple of numbers using the reduce function and a lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def mysum(seq):\n",
    "    ????  # Replace the ???? with your code.\n",
    "\n",
    "mysum((4, 7, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Implement a function `mylength` which uses `map` and `reduce` (or only `reduce`, if you feel like it) to compute the length of a sequence. The use of the `len` function is not allowed.\n",
    "\n",
    "[Hint: You can use `map` to convert the input to something which can easily be `reduce`:d.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Returning functions\n",
    "\n",
    "The previous section covered functions which take other functions as input, but what about the opposite, functions returning functions as output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Function composition is a common in both maths and programming. Write a function `compose` which takes two functions, $f$ and $g$, and produces the _composite_ function $f \\circ g$, where $(f \\circ g)(x) \\Leftrightarrow f(g(x))$. Example use is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statistics import stdev, mean\n",
    "\n",
    "def compose(f, g):\n",
    "    pass   # Replace this with your code.\n",
    "\n",
    "def myscale(vals):\n",
    "    return [x/stdev(vals) for x in vals]\n",
    "\n",
    "def myshift(vals):\n",
    "    return [x-mean(vals) for x in vals]\n",
    "\n",
    "standardize = compose(myscale, myshift)\n",
    "\n",
    "print(standardize(range(-3, 8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voluntary task (not required)**\n",
    "Create a function `composition(*funs)` which takes a non-empty sequence of functions of one argument and returns their sequential composition. That is $composition(f_0,f_1, \\ldots, f_n) = f_0 \\circ f_1 \\circ\\ldots \\circ f_n$. (The question of if $f\\circ g \\circ h$ should be read $f\\circ (g\\circ h)$ or $(f \\circ g) \\circ h$ is perfectly valid, but they turn out to be the same. That is, $\\circ$ is associative.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composition(*funs):\n",
    "    return reduce(???, ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Don't remember what can be found in `*funs`? Print it! Don't know how the values should be combined? Write out some simple example on paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This task demonstrates the generality of our constructs. Previously we worked with sequences of numbers and the like. Now we lift this to the level of working with functions as values, and instead of using combinators which work on numbers, we use function combinators in conjunction with our known patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voluntary task: pipelining\n",
    "\n",
    "When doing data analysis, one very important part is pre-processing. Often, data goes through a number of steps of preprocessing, sometimes called a pipeline. The function composition example above can be seen as a special case of such a pipeline for only two functions. By clever use of higher order functions, we can build a pipeline function which takes a list or tuple of data transforming functions and creates a function which applies these sequentially. Construct such a function called `make_pipeline`. In order to focus on the primary purpose of the `make_pipeline` function, we will perform a very simple set of transformations, increment each value by 1, take the absolute value, and then take the square root. Usage example and code for the `inc` function is supplied below.\n",
    "\n",
    "You may want to use functions you have defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from functools import reduce, partial\n",
    "from math import sqrt \n",
    "\n",
    "\n",
    "def make_pipeline(*funs):\n",
    "    return lambda vals: ???\n",
    "\n",
    "# We can even drop the lambda vals : bit, using partial\n",
    "# evaluation (see the help for functools.partial!)\n",
    "\n",
    "def inc(x):\n",
    "    return x+1\n",
    "\n",
    "pipeline = make_pipeline(inc, abs, sqrt)\n",
    "\n",
    "tuple(pipeline(range(-5,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple declarative Pythonic patterns (involving higher order functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) As preparation, create a named tuple type \"coord\" which has fields `x` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "coord = namedtuple(\"coord\", \"x y\")\n",
    "\n",
    "five_three = coord(5,3)\n",
    "assert five_three.x == 5, \"first element is the x coordinate\"\n",
    "assert five_three.y == 3, \"the second element is the y coordinate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Generate a $10^7$ random coordinates, with $x$ and $y$ coordinates drawn uniformly from [-1000,1000]. Save the tuple of those with $x + y > 0$ as `rnd_coords`. How many are there (probably fewer than $10^7$)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "\n",
    "pass # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Note: If this takes a while, you might want to consider when the elements are generated and saved!]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before having solved the tasks below, consider setting `coords` to a smaller set (eg generate $10^3$ elements instead of $10^7$ to start with).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Let `sorted_rnd` be the coordinated sorted first by the `x` component and then the `y`. Use a built-in Python sorting function. Do you need any extra parameters? Why? Why not? How would you find out where the order comes from (and might it be consistent but useless, eg sorting the elements by memory location)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_rnd = None # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[General words of advice:\n",
    "\n",
    "* During testing, you might want to use a smaller data set (and then try it out at a larger set).\n",
    "* You might not want to display the entire list to see if you're right all the time. Slicing out the first and last elements, say the first or last 10, might provide some hints.\n",
    "* You could naturally define a function which checks that the list is in order (or performs some probabilistic sampling test), to test this.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Sort the values (in the sense of returning a new sorted tuple) by their Euclidean distance to the point (5,3). Continue using a built-in Python sorting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_near_53 = None # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: here we customise the behaviour of a built-in function by passing it information about our intended ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Define the function `sorted_by_distance(origo)` which takes a coordinate `origo` and returns a function which sorts the sequence by the euclidean distance to `origo`. (Ie those closest to origo come first in the list.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_by_distance(origo):\n",
    "    pass\n",
    "\n",
    "ordered_by_closeness_to_53 = sorted_by_distance(coord(5,3))   # Return the function.\n",
    "pts_near_53_2 = ordered_by_closeness_to_53(coords)     # Applying the function \n",
    "\n",
    "assert pts_near_53 == pts_near_53_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Note: Here we extend the work above to a higher-order function, which uses the local value of `origo`. In essence, this task summarises higher order functionality - we create a closure, return a function and use a custom ordering ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) So far in the course, we have seen, and possibly used `enumerate`, `range`, `zip`, `map` and `filter` as declarative constructs (along with the general comprehension syntax). Now we introduce a further useful iterator construct. Construct something called `reverse_squared` which when prompted would give us the squares of elements 0,...,N _but in reverse_ (that is $N^2, (N-1)^2, ..., 2^2, 1^2, 0^2$). You may not give `range` a negative step length in this task (we are interested in more general ways of expressing that we want to iterate in another order, which in this and many cases will prove efficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The time it takes to run this shouldn't really depend on if you use SMALL_N or BIG_N.\n",
    "\n",
    "BIG_N = 99999999\n",
    "SMALL_N = 999\n",
    "\n",
    "N = SMALL_N    # change this to test later on\n",
    "\n",
    "reverse_squares = None # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Experimentation: copy and paste your code from above into this cell.\n",
    "# This is rather crude, but we want you to to be able to trust that any\n",
    "# slowness in the cell above can be found by reference to that code, not the\n",
    "# profiling code below.\n",
    "\n",
    "# Copy-pasting as it might be useful to have fresh maps.\n",
    "\n",
    "import profile\n",
    "\n",
    "# We cut and paste this code \n",
    "BIG_N = 99999999\n",
    "SMALL_N = 999\n",
    "\n",
    "N = SMALL_N    \n",
    "# Look at the run time. Switching from BIG_N to SMALL_N shouldn't really matter.\n",
    "# This suggests that we have quick access to elements at the end of our (squared) range.\n",
    "\n",
    "reverse_squares = None # <<----------- Your code from the cell above goes here.\n",
    "\n",
    "\n",
    "profile.run(\"print(f'Did we find it? ', N**2 in reverse_squares)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: once you know of the construct, this task is extremely simple. It mostly serves as a demonstration of the availability of these constructs, and how they can be combined. Also, it points to efficiency considerations when using declarative iterator constructs as opposed to fixed computed structures.\n",
    "\n",
    "As the profiling code above suggests, where we redefine the object in every run, we do not have a purely functional construct. In that case, we wouldn't be able to exhaust the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Additional reading: some additional tools are available in the `itertools` module.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Mutating function state\n",
    "\n",
    "A function always has access to the environment in which it was created. Usually, this means that the function can access global variables. It also means that it can access and modify local bindings from where it was created.\n",
    "\n",
    "A closure is a function which has access to an environment which is not accessible from outside the function (but which is not destroyed when the function returns). I.e. it is a way to introduce a small measure of statefulness into functional programming. In Python, iterators and generators work much like this. However, we can use the general concept in many cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Implement a function `make_counter` which has a single parameter `n` which acts as the initial value for a counter. The function should return a function with no parameters which, when called, increments the value of `n` by 1 and returns the new value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_counter(n):\n",
    "    yield lambda x: n+1\n",
    "\n",
    "counter_A = make_counter(0)\n",
    "counter_B = make_counter(15)\n",
    "print(\"To show that the functions do not affect each others' states, consider the printout:\")\n",
    "print(f\"counter_A returns: {counter_A()}\")\n",
    "print(f\"counter_A returns: {counter_A()}\")\n",
    "print(f\"counter_B returns: {counter_B()}\")\n",
    "print(f\"counter_A returns: {counter_A()} (was it affected by the call to counter_B?)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution\n",
    "\n",
    "Lab by Johan Falkenjack (2018), extended and rewritten by Anders MÃ¤rak Leffler (2019).\n",
    "\n",
    "License [CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
